[![python - v3.12.8](https://img.shields.io/static/v1?label=python&message=v3.12.8&color=blue&logo=python&logoColor=white)](https://)
[![cuda - v12.1](https://img.shields.io/static/v1?label=cuda&message=v12.1&color=green&logo=nvidia&logoColor=white)](https://)
[![torch - v2.5.1](https://img.shields.io/static/v1?label=torch&message=v2.5.1&color=orange&logo=pytorch&logoColor=white)](https://)

### Repository Summary ###
- Task: Time Series Analysis
- Model Type: Long short-term memory
- Total number of parameters: fuck you (to be filled)
- Total size of the model: my ass (to be filled)

# attention-LSTM
This repo combines LSTM layers with Multi-Head Attention mechanism to capture both sequential dependencies and important feature relationships. The example demonstrates forecasting Bitcoin (BTC) prices using historical data and additional features.
